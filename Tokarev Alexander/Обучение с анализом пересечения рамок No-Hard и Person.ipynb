{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/alecseiterr/Virginia_logistic/blob/main/Alexander_Kulinichenko/%D0%A1%D1%82%D0%B0%D0%B6%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D0%92%D0%B8%D1%80%D0%B4%D0%B6%D0%B8%D0%BD%D0%B8%D1%8F_2023_10_25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"vbg4bsmJR0a3"},"source":["Разметка видео"]},{"cell_type":"markdown","metadata":{"id":"ssFc5HLZUhsN"},"source":["#Загрузка библиотек\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20584,"status":"ok","timestamp":1702843640949,"user":{"displayName":"Alexandr Tokarev","userId":"02431114144541497940"},"user_tz":-180},"id":"Ma8lu6ByUm-v","outputId":"84a6a761-1a8c-46c7-c247-c386c108dfc4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.0.227-py3-none-any.whl (660 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.5/660.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Collecting thop>=0.1.1 (from ultralytics)\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.46.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Installing collected packages: thop, ultralytics\n","Successfully installed thop-0.1.1.post2209072238 ultralytics-8.0.227\n"]}],"source":["!pip install ultralytics"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"SGPG7bJMfe0V","executionInfo":{"status":"ok","timestamp":1702844468224,"user_tz":-180,"elapsed":9409,"user":{"displayName":"Alexandr Tokarev","userId":"02431114144541497940"}}},"outputs":[],"source":["# В случае использования виртуального окружения python, начало будет здесь\n","from ultralytics import YOLO\n","# Для работы в блокноте подключим функцию очистки экрана (можно игнорировать)\n","from IPython.display import clear_output\n","# Используем cv2 для работы с изображениями\n","import cv2\n","#from google.colab.patches import cv2_imshow\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import json\n","import os"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18296,"status":"ok","timestamp":1702844487876,"user":{"displayName":"Alexandr Tokarev","userId":"02431114144541497940"},"user_tz":-180},"id":"w8QRaCLRSw9m","outputId":"e4681b64-44a0-44e3-f525-d8225ca37410"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive # Для работы с Google Drive\n","drive.mount('/content/drive/')\n","directory = '/content/drive/My Drive/ColabData/'"]},{"cell_type":"markdown","metadata":{"id":"_sfnyyDXTA_X"},"source":["#  Рабочий блок"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":254},"executionInfo":{"elapsed":501,"status":"error","timestamp":1702873855778,"user":{"displayName":"Alexandr Tokarev","userId":"02431114144541497940"},"user_tz":-180},"id":"vBZF29gEbvCd","outputId":"e7b0a240-f974-4e8d-c099-7990736918a0"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-e82887545302>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#video_file = directory+'ГС-ЦОД-10 2023-09-15 13-50-31_576.avi'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Куда будем сохранять фотки\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'TestCross/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#save_json = directory+'Bboxes/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Если нет каталога, создадим его\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'directory' is not defined"]}],"source":["# Видео файл\n","#video_file = directory+'ГС-ЦОД-10 2023-09-15 13-50-31_576.avi'\n","# Куда будем сохранять фотки\n","test_dir = directory+'TestCross/'\n","#save_json = directory+'Bboxes/'\n","# Если нет каталога, создадим его\n","#!mkdir {save_dir}\n","#cap = cv2.VideoCapture(video_file)\n","#frames_num=cap.get(cv2.CAP_PROP_FRAME_COUNT)  # number of frames in the video\n","#model = YOLO('yolov8n.pt')\n","model = YOLO(directory+'3best.pt')\n","source='/content/drive/MyDrive/ColabData/Kaski_All/result_yolo33/weights/best.pt'\n","#fpi=100 # period of reading frames from the video / с какой частотой выбираем кадры из видео\n","\n","#i_max=frames_num//(fpi*4) # number of frames to read from the video / максимальное кол-во кадров выборки\n","#i_max=int(i_max*0.28) # берем только первую треть, так как остальное видео - ночь\n","#i_max=10\n","#print('num=',frames_num, 'i_max=',i_max)\n","\n","i=0 # counter of frames\n","i_max=1\n","for image in os.listdir(test_dir):\n","    # Read a frame from the video\n","    #cap.set(cv2.CAP_PROP_POS_FRAMES,i*fpi) # choice of frame in the video / выбираем кадр из видео для считывания\n","    #success, frame = cap.read()\n","    #print('persent=',100*i/i_max) # доля выполненного задания\n","    #img = Image.fromarray(frame[:, :, ::-1])\n","\n","    #if success:\n","        # Run YOLOv8 inference on the frame\n","\n","        results = model(test_dir+image, conf=0.15)#, save=True) # classes = person, probability - 0.1classes=0,\n","        # Visualize the results on the frame\n","        persons_count = results[0].__len__() # number of persons detected\n","        #print(persons_count)\n","        annotated_frame = results[0].plot() # annotated frame\n","          #img = Image.fromarray(frame[:, :, ::-1]) # make image from frame\n","          #display(img) # display for colab\n","\n","        Boxes = results[0].boxes.xywhn  # Boxes object for bbox outputs    .tojson()  xyxyn\n","        Clases=results[0].boxes.cls\n","        print(results[0].boxes.cls,Boxes)\n","          #Boxes_json=results[0].tojson()\n","          #print(Boxes_json)\n","        pers, nohard=[],[]\n","        for j in range(persons_count):\n","            clas=int(Clases[j].item())\n","            print(str(clas)+' '+str(Boxes[j,0].item())+' '+str(Boxes[j,1].item())+' '+str(Boxes[j,2].item())+' '+str(Boxes[j,3].item())+'\\n')#Отладка\n","            lst=[clas,Boxes[j,0].item(),Boxes[j,1].item(),Boxes[j,2].item(),Boxes[j,3].item()]\n","\n","            # рассортировать на две группы No-Hardhat и Person\n","            if clas==1:\n","              nohard.append(lst)\n","            elif clas==2:\n","              pers.append(lst)\n","        print(nohard,pers)\n","          #Boxes_json=Boxes.boxes\n","          # masks = result.masks  # Masks object for segmentation masks outputs\n","          # keypoints = result.keypoints  # Keypoints object for pose outputs\n","          # probs = result.probs  # Probs object for classification outputs\n","          #print('box=', results[0].boxes.xywhn)#Boxes_json)#Boxes.boxes)# )#   good!=       results[0].boxes.xywhn  - good!\n","        img_ann = Image.fromarray(annotated_frame[::4, ::4, ::-1])\n","        display(img_ann) #Display the annotated frame\n","\n","          #cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n","\n","          #cv2.imwrite(f'{save_img}704_{i:06d}.jpg', frame) #saving the image in work dir\n","          #with open(f'{save_json}704_{i:06d}.txt', 'w') as file:\n","          #  for j in range(persons_count):\n","              #file.write('2 '+str(Boxes[j,0].item())+' '+str(Boxes[j,1].item())+' '+str(Boxes[j,2].item())+' '+str(Boxes[j,3].item())+'\\n')\n","          #    file.write(str(results[0].boxes.cls[j])+' '+str(Boxes[j,0].item())+' '+str(Boxes[j,1].item())+' '+str(Boxes[j,2].item())+' '+str(Boxes[j,3].item())+'\\n')\n","             #json.dump(Boxes_json, file, indent=5)\n","          # Break the loop if 'q' is pressed\n","        #else:\n","        #  pass\n","          #cv2.imwrite(f'{save_json}576_{i:06d}.jpg', frame)\n","\n","    #i+=1 # counter + 1\n","        # if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n","        #     break\n","    # else:\n","    #     # Break the loop if the end of the video is reached\n","    #     break\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1700542760227,"user":{"displayName":"Александр Токарев","userId":"02431114144541497940"},"user_tz":-180},"id":"izMAf956OZHd","outputId":"b7e43423-66ec-4bed-a1be-89241e493db5"},"outputs":[{"data":{"text/plain":["<function str.count>"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["dir('runs/detect/predict2')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lvrjnyH7-Z02"},"outputs":[],"source":["# утилита для очистки папки с файлами при проведении экспериментов\n","dir_del=save_json\n","files=os.listdir(dir_del)\n","for file in files:\n","  os.remove(dir_del+file) # clear files"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":489,"status":"ok","timestamp":1700544312377,"user":{"displayName":"Александр Токарев","userId":"02431114144541497940"},"user_tz":-180},"id":"E4_qwCpEGNvY","outputId":"072caa20-360b-4428-e949-a3b9d3d7997f"},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n"]}],"source":["\n","print(len(os.listdir(path=directory+'/Kaski/')))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ymgfF63lfmMV"},"outputs":[],"source":["# это блок для экспериментов распознавание сразу из видео\n","# Видео файл\n","video_file = directory+'ГС-ЦОД-10 2023-09-15 13-50-31_576.avi'\n","# Куда будем сохранять фотки\n","save_dir = directory+'/Kaski/'\n","# Если нет каталога, создадим его\n","#!mkdir {save_dir}\n","cap = cv2.VideoCapture(video_file)\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","print(fps)\n","\n","est_video_length_minutes = 10.28         # Round up if not sure.\n","est_tot_frames = est_video_length_minutes * fps  # Sets an upper bound # of frames in video clip\n","\n","n = 1000                             # Desired interval of frames to include\n","desired_frames = n * np.arange(est_tot_frames)\n","#print(desired_frames)\n","# Берем стандартную модель\n","model = YOLO('yolov8n.pt')\n","\n","for k in desired_frames:\n","  cap.set(1,k-1)\n","  success,img = cap.read(1)\n","  im = Image.fromarray(img)\n","  #im.show()\n","  #display(im)\n","  print('k=',k)\n","# Обнаруживаем только нулевой класс (person) в режиме генератора (stream)\n","  res = model(im, stream=False, classes=0)#, device = '0')  .predict\n","\n","  results = model([im], stream=False, classes=0)  # return a list of Results objects\n","\n","# Process results list\n","  for result in results:\n","      boxes = result.boxes  # Boxes object for bbox outputs\n","      masks = result.masks  # Masks object for segmentation masks outputs\n","      keypoints = result.keypoints  # Keypoints object for pose outputs\n","      probs = result.probs  # Probs object for classification outputs\n","\n","\n","\n","\n","  #for i, r in enumerate(res):\n","  print('box=',boxes)\n","    # При детекции человека\n","  if 2 > 0:\n","      # Получаем изображение, конвертируем в нужное разрешение\n","    img = Image.fromarray(r.orig_img[:, :, ::-1]).resize((480, 640))\n","    display(img)\n","      #img = cv2.resize(img, (1280, 720))\n","      #img = r.orig_img\n","\n","      # plt.figure(figsize=(7,7))\n","      # plt.imshow(res)\n","      # plt.show()\n","\n","      # Сохраняем под номером кадра\n","    i=int(k)\n","    img.save(f'{save_dir}data1_{i:06d}.jpg')\n","      #cv2.imwrite(f'{save_dir}data1_{i:06d}.jpg', img, [1, 60] )\n","      #cv2.imwrite(f'{save_dir}data5_{i:06d}.jpg', img)\n","  if k>500:\n","      break\n","\n","# with open(with open(f'{save_json}576_{i:06d}.json') as json_file:\n","#     data = json.load(json_file)\n","#     for p in data['people']:\n","#         print('Name: ' + p['name'])\n","#         print('Website: ' + p['website'])\n","#         print('From: ' + p['from'])\n","#         print('')\n","\n","# Очищаем экран\n","#clear_output()"]}],"metadata":{"colab":{"provenance":[{"file_id":"1PnGHLn9M5q7pQPEQirT4PLQknoIwIm1u","timestamp":1702842456706},{"file_id":"1yX4OIW8J6u0BcBA9NnowKBV2v0UJXoxV","timestamp":1699992953893},{"file_id":"160q2wZtgk-1w1qVQuhXSA_1bzar0qJqQ","timestamp":1699783041701}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}